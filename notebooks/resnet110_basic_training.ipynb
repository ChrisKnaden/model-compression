{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-07T13:06:26.462352Z",
     "start_time": "2025-04-07T13:06:25.414911Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from src.utils import load_model, save_model\n",
    "from src.data_loader import get_cifar10_loader\n",
    "from src.train import train_model\n",
    "from src.model import ResNet, BasicBlock, resnet110\n",
    "from src.evaluate import evaluate\n",
    "from src.utils import count_total_parameters\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:06:27.142048Z",
     "start_time": "2025-04-07T13:06:26.970513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "device = torch.device(\"mps\")\n",
    "model_path = \"models/resnet110_baseline_30_mps.pth\"\n",
    "#model = resnet110() # Until I pretrained the model aha\n",
    "model = load_model(model_path, device=device)\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n"
   ],
   "id": "2135f14d19b1aa26",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:06:30.102443Z",
     "start_time": "2025-04-07T13:06:28.817131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define optimizer and criterion for training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load data\n",
    "train_loader = get_cifar10_loader('train', batch_size=batch_size)\n",
    "val_loader = get_cifar10_loader('val', batch_size=batch_size)"
   ],
   "id": "139eb83ab5fd5fae",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T12:58:39.195410Z",
     "start_time": "2025-04-07T12:57:15.412676Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, train_loader, optimizer, criterion, device, num_epochs=num_epochs)\n",
   "id": "810d3012b4f1a00e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:10:15.044370Z",
     "start_time": "2025-04-07T13:10:10.224383Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate(model, val_loader, device)\n",
   "id": "aa4c78d09a37a43a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 86.57%, Avg Loss: 0.4323, Time: 4.81s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(86.57, 0.4322943902492523)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T13:01:23.232428Z",
     "start_time": "2025-04-07T13:01:23.184517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the full pruned model after all pruning steps\n",
    "save_model(model, model_path)"
   ],
   "id": "5305b4d29d5f5583",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T10:12:47.222490Z",
     "start_time": "2025-04-07T10:12:47.031080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "model = load_model(model_path, device=device)\n"
   ],
   "id": "ee7e3f3c9e6fabec",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/christophknaden/git/model-compression/resnet110_baseline_30_mps.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Load the full pruned model\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m model = \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Set the model to evaluation mode (or training mode as needed)\u001B[39;00m\n\u001B[32m      5\u001B[39m model.eval()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/model-compression/src/utils.py:22\u001B[39m, in \u001B[36mload_model\u001B[39m\u001B[34m(relative_path, device, weights_only)\u001B[39m\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(device, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m     20\u001B[39m     device = torch.device(device)\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m checkpoint = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m weights_only:\n\u001B[32m     25\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m checkpoint.get(\u001B[33m\"\u001B[39m\u001B[33mmodel_state_dict\u001B[39m\u001B[33m\"\u001B[39m, checkpoint)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/model-compression/.venv/lib/python3.11/site-packages/torch/serialization.py:1425\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[39m\n\u001B[32m   1422\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args.keys():\n\u001B[32m   1423\u001B[39m     pickle_load_args[\u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1425\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[32m   1426\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[32m   1427\u001B[39m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[32m   1428\u001B[39m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[32m   1429\u001B[39m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[32m   1430\u001B[39m         orig_position = opened_file.tell()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/model-compression/.venv/lib/python3.11/site-packages/torch/serialization.py:751\u001B[39m, in \u001B[36m_open_file_like\u001B[39m\u001B[34m(name_or_buffer, mode)\u001B[39m\n\u001B[32m    749\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[32m    750\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[32m--> \u001B[39m\u001B[32m751\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    752\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    753\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/git/model-compression/.venv/lib/python3.11/site-packages/torch/serialization.py:732\u001B[39m, in \u001B[36m_open_file.__init__\u001B[39m\u001B[34m(self, name, mode)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[32m--> \u001B[39m\u001B[32m732\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '/Users/christophknaden/git/model-compression/resnet110_baseline_30_mps.pth'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e9139fe6636f14d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
