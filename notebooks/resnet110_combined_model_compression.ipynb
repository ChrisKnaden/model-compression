{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pipeline for Multiple Model Compression Techniques\n",
    "This pipeline will demonstrate pruning, quantization, knowledge distillation and their combination. At the end there will be an evaluation of different models."
   ],
   "id": "cd874c09e343260a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "c075a17abf2d43ff"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:08.715511Z",
     "start_time": "2025-04-12T23:27:07.087696Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch_pruning as tp\n",
    "import pandas as pd\n",
    "from src.model import ResNet, BasicBlock, resnet110\n",
    "from src.utils import load_model, save_model, iterative_pruner, load_quantized_model\n",
    "from src.data_loader import get_cifar10_loader\n",
    "from src.train import train_model, train_model_kd, loss_fn_kd, KDParams\n",
    "from src.evaluate import evaluate, measure_inference_time, count_total_parameters, evaluate_model_all_metrics, estimate_model_memory_footprint_from_bits\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Base Parameters",
   "id": "fba38a3ea3f5aa91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:09.985165Z",
     "start_time": "2025-04-12T23:27:09.982962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "model_path = \"models/resnet110_baseline_30_mps.pth\"\n",
    "\n",
    "batch_size = 128\n"
   ],
   "id": "e03025e7312c101c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pruning",
   "id": "9b8d9635e0a848de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:11.369283Z",
     "start_time": "2025-04-12T23:27:11.176199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load base model\n",
    "model = load_model(model_path, device)\n",
    "pruned_model = model\n",
    "\n",
    "count_total_parameters(model)\n",
    "\n",
    "# Channel sparsity / Pruning ratio\n",
    "# ch_sparsity = 0.15 -> 1228878 ca. 30%\n",
    "# ch_sparsity = 0.29 -> 848388  ca. 50%\n",
    "# ch_sparsity = 0.45 -> 509972  ca. 70%\n",
    "# ch_sparsity = 0.95 -> 6765    ca. 0.39%\n",
    "\n",
    "ch_sparsity = 0.45\n",
    "iterative_pruning_steps = 5"
   ],
   "id": "c95bb761d011601e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 1730714\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:12.696638Z",
     "start_time": "2025-04-12T23:27:11.916225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For pruning the model has to be on the cpu\n",
    "pruned_model.to(\"cpu\")\n",
    "example_inputs = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# Importance Criterion\n",
    "imp = tp.importance.TaylorImportance()\n",
    "\n",
    "# Initialization of pruner\n",
    "pruner = tp.pruner.MagnitudePruner(\n",
    "    pruned_model,\n",
    "    example_inputs,\n",
    "    importance=imp,\n",
    "    iterative_steps=iterative_pruning_steps,\n",
    "    ch_sparsity=ch_sparsity,\n",
    ")\n",
    "\n",
    "# Actual pruning\n",
    "iterative_pruner(pruner, iterative_pruning_steps)\n"
   ],
   "id": "dfdbf22fe9209e13",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophknaden/git/model-compression/.venv/lib/python3.11/site-packages/torch_pruning/pruner/algorithms/base_pruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:12.705457Z",
     "start_time": "2025-04-12T23:27:12.702073Z"
    }
   },
   "cell_type": "code",
   "source": "count_total_parameters(pruned_model)",
   "id": "75b0d634b11bb47d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 509972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "509972"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Quantization",
   "id": "f61e89ddc032b239"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:12.956721Z",
     "start_time": "2025-04-12T23:27:12.954871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quantization requires to be made on the cpu\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Set the quantization backend to 'qnnpack', which is optimized for ARM CPUs (e.g., mobile devices)\n",
    "# This enables efficient int8 operations during inference using PyTorch Mobile\n",
    "backend = 'qnnpack'\n"
   ],
   "id": "e4006b44aa119d07",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:14.526719Z",
     "start_time": "2025-04-12T23:27:13.189281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load base model again\n",
    "model = load_model(model_path, device=device)\n",
    "\n",
    "# Load data\n",
    "val_loader = get_cifar10_loader('val', batch_size=batch_size)\n",
    "val_loader_subset = get_cifar10_loader('val', batch_size=batch_size, subset_size=1000)"
   ],
   "id": "70b6d6f1da1888a4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:20.680542Z",
     "start_time": "2025-04-12T23:27:14.530416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(device=device)\n",
    "\n",
    "# Set the backend\n",
    "torch.backends.quantized.engine = backend\n",
    "\n",
    "model_fp32 = model\n",
    "model_fp32.eval()\n",
    "\n",
    "# Fuse modules (e.g., Conv+BN+ReLU) for better quantization accuracy\n",
    "model_fp32.fuse_model()\n",
    "\n",
    "# Set the quantization config for the model\n",
    "model_fp32.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "\n",
    "# Insert observers for calibration\n",
    "model_fp32_prepared = torch.quantization.prepare(model_fp32, inplace = False)\n",
    "\n",
    "# Run the model to collect activation stats for quantization\n",
    "evaluate(model_fp32_prepared, val_loader_subset, device)\n",
    "\n",
    "# Convert the calibrated model to quantized version\n",
    "model_quantized = torch.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "# Custom function to quantize model\n",
    "# model_quantized = quantize_model(model, val_loader_subset, device, backend=backend)"
   ],
   "id": "a22687c0342bfb7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 87.00%, Avg Loss: 0.4502, Time: 5.57s\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:27:48.577896Z",
     "start_time": "2025-04-12T23:27:20.691390Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate(model_quantized, val_loader, device)",
   "id": "70a239bc2a432587",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 86.08%, Avg Loss: 0.4575, Time: 27.88s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(86.08, 0.45750905919075013, 27.88299798965454)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:29:10.329655Z",
     "start_time": "2025-04-12T23:27:48.589088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Measure and compare inference time for float and quantized models\n",
    "time_float = measure_inference_time(model, val_loader, device=device)\n",
    "time_quant = measure_inference_time(model_quantized, val_loader, device=device)\n",
    "\n",
    "print(f\"Average inference time per batch (float model): {time_float:.4f} seconds\")\n",
    "print(f\"Average inference time per batch (quantized model): {time_quant:.4f} seconds\")\n"
   ],
   "id": "735a2b36051a0319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time per batch (float model): 0.4558 seconds\n",
      "Average inference time per batch (quantized model): 0.3012 seconds\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Knowledge Distillation",
   "id": "4ef0e1ef416c9051"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:31:50.386219Z",
     "start_time": "2025-04-12T23:31:50.383376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set device to GPU for faster training\n",
    "device = torch.device(\"mps\")\n",
    "teacher_model_path = \"models/resnet110_baseline_30_mps.pth\"\n",
    "student_model_path = \"models/pruned_95-30_resnet110_mps.pth\"\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "kd_alpha = 0.7\n",
    "kd_temperature = 4.0\n"
   ],
   "id": "24a011c325679060",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:31:52.549305Z",
     "start_time": "2025-04-12T23:31:50.901934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load pretrained models\n",
    "teacher_model = load_model(teacher_model_path, device=device)\n",
    "student_model = load_model(student_model_path, device=device)\n",
    "\n",
    "# Define optimizer and criterion for training\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load data\n",
    "train_loader = get_cifar10_loader('train', batch_size=batch_size)\n",
    "val_loader = get_cifar10_loader('val', batch_size=batch_size)\n",
    "\n",
    "# Set alpha and temperature parameters for Knowledge Distillation\n",
    "kd_params = KDParams(alpha=kd_alpha, temperature=kd_temperature)\n"
   ],
   "id": "f777e36d1aef5718",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:31:54.645015Z",
     "start_time": "2025-04-12T23:31:52.845138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Student accuracy before\n",
    "evaluate(student_model, val_loader, device)"
   ],
   "id": "ce45765e1039d49a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 42.63%, Avg Loss: 1.5419, Time: 1.79s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42.63, 1.5419314538955688, 1.7944419384002686)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:31:40.749574Z",
     "start_time": "2025-04-12T23:30:32.359338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Actual Knowledge Distillation\n",
    "train_model_kd(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    kd_params=kd_params,\n",
    "    num_epochs=num_epochs,\n",
    "    loss_fn_kd=loss_fn_kd\n",
    ")\n"
   ],
   "id": "cdbc1ae72da89ea1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T23:31:43.441278Z",
     "start_time": "2025-04-12T23:31:40.793467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Student accuracy after\n",
    "evaluate(student_model, val_loader, device)"
   ],
   "id": "8f7e1a9d7ee6f344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 40.70%, Avg Loss: 1.6044, Time: 2.64s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40.7, 1.604372562789917, 2.637606143951416)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparison of Model Compression Techniques\n",
   "id": "429b8c7eb5f46d84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T22:19:08.495932Z",
     "start_time": "2025-04-12T22:14:25.908662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use GPU for unquantized models\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "base_model_path = \"models/resnet110_baseline_30_mps.pth\"\n",
    "pruned_model_50_path = \"models/pruned_29-30_resnet110_mps.pth\"\n",
    "pruned_model_70_path = \"models/pruned_45-30_resnet110_mps.pth\"\n",
    "base_quantized_model_path = \"models/quantized_resnet110_baseline_30_cpu.pt\"\n",
    "pruned_kd_model_70_path = \"models/pruned_45-30_kd_10_resnet110_mps.pth\"\n",
    "pruned_kd_quantized_model_70_path = \"models/quantized_pruned_45-30_kd_10_resnet110_cpu.pt\"\n",
    "\n",
    "base_model = load_model(teacher_model_path, device=device)\n",
    "pruned_model_50 = load_model(pruned_model_50_path, device=device)\n",
    "pruned_model_70 = load_model(pruned_model_70_path, device=device)\n",
    "pruned_kd_model_30 = load_model(pruned_kd_model_70_path, device=device)\n",
    "\n",
    "results = {}\n",
    "\n",
    "results[\"Base Model\"] = evaluate_model_all_metrics(base_model, val_loader, device,base_model_path)\n",
    "results[\"Pruned 50%\"] = evaluate_model_all_metrics(pruned_model_50, val_loader, device, pruned_model_50_path)\n",
    "results[\"Pruned 70%\"] = evaluate_model_all_metrics(pruned_model_70, val_loader, device, pruned_model_70_path)\n",
    "results[\"Pruned + KD 70%\"] = evaluate_model_all_metrics(pruned_kd_model_30, val_loader, device, pruned_kd_model_70_path)\n",
    "\n",
    "# Quantized model only works on cpu\n",
    "device = torch.device(\"cpu\")\n",
    "base_quantized_model_30 = load_quantized_model(base_quantized_model_path)\n",
    "pruned_kd_quantized_model_30 = load_quantized_model(pruned_kd_quantized_model_70_path)\n",
    "\n",
    "results[\"Base Quantized\"] = evaluate_model_all_metrics(base_quantized_model_30, val_loader, device, base_quantized_model_path)\n",
    "# As the quantized model is loaded as \"scripted\" (no PyTorch nn.Module),\n",
    "# the model parameters cannot be correctly retrieved. For this purpose, we set it manually\n",
    "results[\"Base Quantized\"][\"parameters\"] = 1730714\n",
    "results[\"Base Quantized\"][\"memory_footprint\"] = estimate_model_memory_footprint_from_bits(1730714, bits=8)\n",
    "\n",
    "results[\"Pruned + KD + Quantized 70%\"] = evaluate_model_all_metrics(pruned_kd_quantized_model_30, val_loader, device, pruned_kd_quantized_model_70_path)\n",
    "# As the quantized model is loaded as \"scripted\" (no PyTorch nn.Module),\n",
    "# the model parameters cannot be correctly retrieved. For this purpose, we set the following manually\n",
    "results[\"Pruned + KD + Quantized 70%\"][\"parameters\"] = 509972\n",
    "results[\"Pruned + KD + Quantized 70%\"][\"memory_footprint\"] = estimate_model_memory_footprint_from_bits(509972, bits=8)"
   ],
   "id": "7fd963b9f4e13ab2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 86.57%, Avg Loss: 0.4323, Time: 5.15s\n",
      "Total number of parameters in the model: 1730714\n",
      "Validation Accuracy: 87.88%, Avg Loss: 0.4254, Time: 4.34s\n",
      "Total number of parameters in the model: 848388\n",
      "Validation Accuracy: 84.10%, Avg Loss: 0.5485, Time: 3.08s\n",
      "Total number of parameters in the model: 509972\n",
      "Validation Accuracy: 86.62%, Avg Loss: 0.4247, Time: 2.88s\n",
      "Total number of parameters in the model: 509972\n",
      "Validation Accuracy: 86.08%, Avg Loss: 0.4575, Time: 35.52s\n",
      "Total number of parameters in the model: 192\n",
      "Validation Accuracy: 86.65%, Avg Loss: 0.4277, Time: 20.25s\n",
      "Total number of parameters in the model: 104\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T22:24:06.446030Z",
     "start_time": "2025-04-12T22:24:06.440405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aggregate results in Data Frame\n",
    "results_table = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy (%)\": f\"{metrics['accuracy']:.2f}\",\n",
    "        \"Parameters\": f\"{metrics['parameters']:,.0f}\",\n",
    "        \"Inference Time (s)\": f\"{metrics['inference_time']:.4f}\",\n",
    "        \"Memory Footprint (MB)\": f\"{metrics['memory_footprint']:.5f}\",\n",
    "        \"File Size (MB)\": f\"{metrics['file_size']:.2f}\"\n",
    "    }\n",
    "    for model_name, metrics in results.items()\n",
    "])\n",
    "\n",
    "# Display the table\n",
    "results_table = results_table.set_index(\"Model\")\n",
    "display(results_table)\n"
   ],
   "id": "9f5fe8e96af1abf7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            Accuracy (%) Parameters Inference Time (s)  \\\n",
       "Model                                                                    \n",
       "Base Model                         86.57  1,730,714             0.5238   \n",
       "Pruned 50%                         87.88    848,388             0.3654   \n",
       "Pruned 70%                         84.10    509,972             0.2565   \n",
       "Pruned + KD 70%                    86.62    509,972             0.2523   \n",
       "Base Quantized                     86.08  1,730,714             0.3384   \n",
       "Pruned + KD + Quantized 70%        86.65    509,972             0.1889   \n",
       "\n",
       "                            Memory Footprint (MB) File Size (MB)  \n",
       "Model                                                             \n",
       "Base Model                                6.60215           6.92  \n",
       "Pruned 50%                                3.23634           3.54  \n",
       "Pruned 70%                                1.94539           2.24  \n",
       "Pruned + KD 70%                           1.94539           2.25  \n",
       "Base Quantized                            1.65054           1.77  \n",
       "Pruned + KD + Quantized 70%               0.48635           0.61  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "      <th>Memory Footprint (MB)</th>\n",
       "      <th>File Size (MB)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Model</th>\n",
       "      <td>86.57</td>\n",
       "      <td>1,730,714</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>6.60215</td>\n",
       "      <td>6.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned 50%</th>\n",
       "      <td>87.88</td>\n",
       "      <td>848,388</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>3.23634</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned 70%</th>\n",
       "      <td>84.10</td>\n",
       "      <td>509,972</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>1.94539</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned + KD 70%</th>\n",
       "      <td>86.62</td>\n",
       "      <td>509,972</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>1.94539</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Quantized</th>\n",
       "      <td>86.08</td>\n",
       "      <td>1,730,714</td>\n",
       "      <td>0.3384</td>\n",
       "      <td>1.65054</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned + KD + Quantized 70%</th>\n",
       "      <td>86.65</td>\n",
       "      <td>509,972</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.48635</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T22:54:37.625524Z",
     "start_time": "2025-04-12T22:54:37.616390Z"
    }
   },
   "cell_type": "code",
   "source": "results_table.to_csv(\"../notebooks/data/model_metrics.csv\")\n",
   "id": "e76d18138e4a7542",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T22:54:39.040417Z",
     "start_time": "2025-04-12T22:54:39.030725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_table = pd.read_csv(\"../notebooks/data/model_metrics.csv\", index_col=\"Model\")\n",
    "display(results_table)"
   ],
   "id": "789a995fbdd7f13b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             Accuracy (%) Parameters  Inference Time (s)  \\\n",
       "Model                                                                      \n",
       "Base Model                          86.57  1,730,714              0.5238   \n",
       "Pruned 50%                          87.88    848,388              0.3654   \n",
       "Pruned 70%                          84.10    509,972              0.2565   \n",
       "Pruned + KD 70%                     86.62    509,972              0.2523   \n",
       "Base Quantized                      86.08  1,730,714              0.3384   \n",
       "Pruned + KD + Quantized 70%         86.65    509,972              0.1889   \n",
       "\n",
       "                             Memory Footprint (MB)  File Size (MB)  \n",
       "Model                                                               \n",
       "Base Model                                 6.60215            6.92  \n",
       "Pruned 50%                                 3.23634            3.54  \n",
       "Pruned 70%                                 1.94539            2.24  \n",
       "Pruned + KD 70%                            1.94539            2.25  \n",
       "Base Quantized                             1.65054            1.77  \n",
       "Pruned + KD + Quantized 70%                0.48635            0.61  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Inference Time (s)</th>\n",
       "      <th>Memory Footprint (MB)</th>\n",
       "      <th>File Size (MB)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Model</th>\n",
       "      <td>86.57</td>\n",
       "      <td>1,730,714</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>6.60215</td>\n",
       "      <td>6.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned 50%</th>\n",
       "      <td>87.88</td>\n",
       "      <td>848,388</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>3.23634</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned 70%</th>\n",
       "      <td>84.10</td>\n",
       "      <td>509,972</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>1.94539</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned + KD 70%</th>\n",
       "      <td>86.62</td>\n",
       "      <td>509,972</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>1.94539</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Quantized</th>\n",
       "      <td>86.08</td>\n",
       "      <td>1,730,714</td>\n",
       "      <td>0.3384</td>\n",
       "      <td>1.65054</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pruned + KD + Quantized 70%</th>\n",
       "      <td>86.65</td>\n",
       "      <td>509,972</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>0.48635</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
