{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.ao.nn.quantized import FloatFunctional\n",
    "\n",
    "'''\n",
    "Properly implemented ResNet-s for CIFAR10 as described in paper [1].\n",
    "\n",
    "The implementation and structure of this file is hugely influenced by [2]\n",
    "which is implemented for ImageNet and doesn't have option A for identity.\n",
    "Moreover, most of the implementations on the web is copy-paste from\n",
    "torchvision's resnet and has wrong number of params.\n",
    "\n",
    "Proper ResNet-s for CIFAR10 (for fair comparision and etc.) has following\n",
    "number of layers and parameters:\n",
    "\n",
    "name      | layers | params\n",
    "ResNet20  |    20  | 0.27M\n",
    "ResNet32  |    32  | 0.46M\n",
    "ResNet44  |    44  | 0.66M\n",
    "ResNet56  |    56  | 0.85M\n",
    "ResNet110 |   110  |  1.7M\n",
    "ResNet1202|  1202  | 19.4m\n",
    "\n",
    "which this implementation indeed has.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "[2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "If you use this implementation in you work, please don't forget to mention the\n",
    "author, Yerlan Idelbayev.\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='B'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.ff = FloatFunctional() # To make it ready for quantization\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A': # Option A does not work with torch-pruning, as the LambdaLayer cannot be analysed. Therefore we use option B\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.ff.add(out, self.shortcut(x)) # remove + for quantization\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.quant(x) # add quant\n",
    "        out = F.relu(self.bn1(self.conv1(out)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = self.dequant(out) # add dequant\n",
    "        return out\n",
    "\n",
    "    def fuse_model(self):\n",
    "        torch.quantization.fuse_modules(self, [['conv1', 'bn1']], inplace=True)\n",
    "        for m in self.layer1:\n",
    "            torch.quantization.fuse_modules(m, [['conv1', 'bn1'], ['conv2', 'bn2']], inplace=True)\n",
    "        for m in self.layer2:\n",
    "            torch.quantization.fuse_modules(m, [['conv1', 'bn1'], ['conv2', 'bn2']], inplace=True)\n",
    "        for m in self.layer3:\n",
    "            torch.quantization.fuse_modules(m, [['conv1', 'bn1'], ['conv2', 'bn2']], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "\n",
    "def resnet32():\n",
    "    return ResNet(BasicBlock, [5, 5, 5])\n",
    "\n",
    "\n",
    "def resnet44():\n",
    "    return ResNet(BasicBlock, [7, 7, 7])\n",
    "\n",
    "\n",
    "def resnet56():\n",
    "    return ResNet(BasicBlock, [9, 9, 9])\n",
    "\n",
    "\n",
    "def resnet110():\n",
    "    return ResNet(BasicBlock, [18, 18, 18])\n",
    "\n",
    "\n",
    "def resnet1202():\n",
    "    return ResNet(BasicBlock, [200, 200, 200])\n",
    "\n",
    "\n",
    "def test(net):\n",
    "    import numpy as np\n",
    "    total_params = 0\n",
    "\n",
    "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
    "        total_params += np.prod(x.data.numpy().shape)\n",
    "    print(\"Total number of params\", total_params)\n",
    "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    for net_name in __all__:\n",
    "#        if net_name.startswith('resnet'):\n",
    "#            print(net_name)\n",
    "#            test(globals()[net_name]())\n",
    "#            print()"
   ],
   "id": "642108a94c31f75f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from contextlib import nullcontext\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    use_amp = True\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    use_amp = False\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    use_amp = False\n",
    "\n",
    "try:\n",
    "    from torch.amp import autocast, GradScaler\n",
    "except ImportError:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Loss wrapper for KD\n",
    "class KDParams:\n",
    "    def __init__(self, alpha=0.9, temperature=4.0):\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "def loss_fn_kd(student_outputs, labels, teacher_outputs, params):\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    T = params.temperature\n",
    "    alpha = params.alpha\n",
    "\n",
    "    kd_loss = F.kl_div(\n",
    "        F.log_softmax(student_outputs / T, dim=1),\n",
    "        F.softmax(teacher_outputs / T, dim=1),\n",
    "        reduction='batchmean'\n",
    "    ) * (alpha * T * T)\n",
    "\n",
    "    ce_loss = F.cross_entropy(student_outputs, labels) * (1. - alpha)\n",
    "    return kd_loss + ce_loss\n",
    "\n",
    "def train_model_kd(student_model, teacher_model, train_loader, optimizer, device,\n",
    "                   loss_fn_kd, kd_params, num_epochs=10, use_amp=False):\n",
    "\n",
    "    # Disable AMP for MPS/CPU\n",
    "    if device.type != 'cuda':\n",
    "        use_amp = False\n",
    "\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "\n",
    "    scaler = GradScaler(enabled=(use_amp and device.type == 'cuda'))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        student_model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Choose context: autocast for CUDA, nullcontext otherwise\n",
    "            amp_context = autocast(device_type='cuda') if use_amp and device.type == 'cuda' else nullcontext()\n",
    "\n",
    "            with amp_context:\n",
    "                student_outputs = student_model(inputs)\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "                loss = loss_fn_kd(student_outputs, targets, teacher_outputs, kd_params)\n",
    "\n",
    "            if use_amp and device.type == 'cuda':\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = student_outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            acc = 100. * correct / total\n",
    "            avg_loss = running_loss / (progress_bar.n + 1)\n",
    "            progress_bar.set_postfix(loss=f\"{avg_loss:.4f}\", acc=f\"{acc:.2f}%\")"
   ],
   "id": "f6f1c3007800ddff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "def get_cifar10_loader(split='train', batch_size=128, workers=0, subset_size=0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        split (str): 'train' or 'val'\n",
    "        batch_size (int): Batch size for DataLoader\n",
    "        workers (int): Number of worker threads\n",
    "        subset_size (int): If > 0, return a subset of the dataset\n",
    "    \"\"\"\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    if split == 'train':\n",
    "        dataset = datasets.CIFAR10(\n",
    "            root='./data', train=True,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomCrop(32, 4),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]), download=True)\n",
    "        shuffle = True\n",
    "    elif split == 'val':\n",
    "        dataset = datasets.CIFAR10(\n",
    "            root='./data', train=False,\n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ]), download=True)\n",
    "        shuffle = False\n",
    "    else:\n",
    "        raise ValueError(\"split must be either 'train' or 'val'\")\n",
    "\n",
    "    if subset_size > 0:\n",
    "        dataset = torch.utils.data.Subset(dataset, range(subset_size))\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size,\n",
    "        shuffle=shuffle, num_workers=workers,\n",
    "        pin_memory=True)\n",
    "\n",
    "    return loader\n"
   ],
   "id": "7a03d4a31028c493"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the full pruned model\n",
    "teacher_model = torch.load(\"pruned_34-30_resnet110_mps.pth\", map_location=torch.device('mps'), weights_only=False)\n",
    "pruned_model = torch.load(\"pruned_50_resnet110.pth\", map_location=torch.device('mps'), weights_only=False)\n",
    "# Set the model to evaluation mode (or training mode as needed)\n",
    "pruned_model.eval()\n",
    "print(\"Pruned model loaded successfully.\")\n"
   ],
   "id": "d5b6002b374c671e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(pruned_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_loader = get_cifar10_loader('train', batch_size=128)\n",
    "val_loader = get_cifar10_loader('val', batch_size=128)\n",
    "val_loader_subset = get_cifar10_loader('val', batch_size=128, subset_size=1000)\n"
   ],
   "id": "b3babbe1ea5f082f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "kd_params = KDParams(alpha=0.7, temperature=4.0)\n",
    "train_model_kd(\n",
    "    student_model=pruned_model,\n",
    "    teacher_model=teacher_model,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    loss_fn_kd=loss_fn_kd,\n",
    "    kd_params=kd_params,\n",
    "    num_epochs=10,\n",
    "    use_amp=False\n",
    ")\n"
   ],
   "id": "4cf0712dc89f4dfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(model, val_loader, device, use_half=False):\n",
    "    import time\n",
    "    import torch.nn as nn\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    model.eval().to(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    start = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            if use_half:\n",
    "                inputs = inputs.half()\n",
    "                criterion = criterion.half()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            total_loss += loss.item() * targets.size(0)\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    avg_loss = total_loss / total\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%, Avg Loss: {avg_loss:.4f}, Time: {elapsed:.2f}s\")\n",
    "    return acc, avg_loss\n"
   ],
   "id": "11f9251d87a9f8e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "evaluate(pruned_model, val_loader, \"mps\")",
   "id": "b06aec5fb79f072a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43afb94b83bfd15a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
